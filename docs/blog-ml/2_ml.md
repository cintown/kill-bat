# 第二章：相关概念

## 一. 数据
举例[鸢尾花数据]()：

![ml_2_1](https://s2.ax1x.com/2020/01/06/lymK0A.md.png)

![ml_2_2](https://s2.ax1x.com/2020/01/06/lynUgO.png)

### 1. 数据整体叫数据集（data set）
### 2. 每一行数据成为一个样本（sample）
### 3. 除最后结果列，每一列表达样本的一个特征（feature）
![ml_2_3](https://s2.ax1x.com/2020/01/06/lynHP0.md.png)
### 4. 最后一列，称为标记（label）
用小写y表示（通常用大写字母表示矩阵，小写字母表示向量）<br>
![ml_2_4](https://s2.ax1x.com/2020/01/06/lyumdA.png)
### 5. 具体每一行，称为特征向量（X^(i)）

### 6. 特征空间
![ml_2_5](https://s2.ax1x.com/2020/01/06/lyuQRf.md.png)

### 7. 分类任务的本质就是在特征空间切分

## 二. 主要任务
### 1. 分类任务
#### 1.1 二分类任务
* 垃圾邮件
* 股票涨跌

#### 1.2 多分类任务
* 数字识别
* 图像识别

### 2. 回归任务
* 结果是一个连续数字的值，而非一个类别
* 一些情况下，回归任务可以简化为分类任务

 
## 三. 学习方法

### 1. 监督学习
* 给机器的训练数据拥有“标记”或者“答案”
* 监督学习处理之前介绍的“分类任务”的“回归任务”

#### 1.1 监督学习算法
* k近邻
* 线性回归和多项式回归
* 逻辑回归
* SVM
* 决策树和随机森林

### 2.  非监督学习
* 训练数据没有“标记”或“答案”
* 对数据进行降维处理
> 1. 特征提取<br>
> 2. 特征压缩:尽量少的损失信息情况下，将高维特征向量压缩成低维的特征向量。如：PCA<br>
> 3. 可视化<br>
> 4. 异常检测

#### 2.1 聚类分析

### 3. 半监督学习
* 部分数据有“标记”和“答案”
* 更为常见
* 通常先使用无监督学习手段对数据做处理，时候使用监督学习手段做模型的训练和预测

### 4. 增强学习
* 根据周围环境的情况，采取行动，根据采取行动的结果，学习行动方式
![ml_2_6](https://s2.ax1x.com/2020/01/06/lyuNon.md.png)

## 四. 学习的其他分类
### 1. 批量学习
* 优点： 简单
* 问题： 如何适应环境变化？
* 解决：定时重新批量学习
* 缺点：每次重新批量学习，运算量巨大。在某些环境变化非常快的情况下是不可能的

### 2. 在线学习
![ml_2_7](https://s2.ax1x.com/2020/01/06/lyufW6.md.png)
* 优点：及时反映新的环境变化
* 问题：新的数据带来不好的变化
* 解决：需要加强对数据进行监控
* 其他：也适用与数据量巨大，完全无法批量学习的环境

### 3. 参数学习
* 一旦学习了参数，就不再需要原有的数据集

### 4. 非参数学习
* 不对模型进行过多的假设
* 非参数不等于没参数


<comment/>
