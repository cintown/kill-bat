# 第十一章：梯度下降法

## 一. 作用
1. 梯度下降法是一个基于搜索的最优化方法
2. 适用于没有数学特征的算法
3. 最小化一个损失函数
4. 相反，最大化一个效用函数应使用梯度上升法

## 二. 图解
![ml-11-1](https://s2.ax1x.com/2020/01/08/lgXD6P.md.png)
![image](FA1E2C3831EF44F4BFF2F85B09425D5F)
![image](C4826CAFF1604147AE140378B3A462B3)
![image](4B13AB1729EA4C05B83667B718363DCA)
* 对于高维函数
![image](FE564EA228A441B8BA85BD5BF422728A)
* 有可能找到的解不是全局最优解
* 解决这个问题的方法是，多次运行

## 三. 线性回归使用梯度下降法
* 线性回归损失函数的梯度是一个向量
![image](1F25B81175AB4D2DA438B9FF2CAC1297)
![image](0E6A6588452849B5A08E1C68FA6843C4)
* 同样使用我们在线性回归中技巧，将yhead整理成两个向量相乘的模式
![image](14F57676F3A0400580455010C457914B)
* 我们可以观察到m数量对梯度是有影响的，所以我们考虑到将目标函数除以m
![image](67DDB410A0E445C49DA179DD190AFA96)


## 四. 向量化
![image](3E64041AA6394AD283A3C31B30203CA7)
![image](F391965F95E24BF8822CCCB71248FA94)
* 我们得到结果
![image](7C7CE647D42B4A7A95EAF31F57141CA5)

> 在梯度下降前，应对数据进行归一化

![image](5DF82E53A8854B2C984D247D644706DA)

## 五. 随机梯度下降法

### 1. 批量梯度下降法的问题
* 计算量与m相关，但是我们又除以了m
* 有没有可能将sigma去掉，我们只取一个方向的损失函数的最小值

### 2. 图示
![image](0635B0910A904F7EA169848AC81BDD7D)
* 这个超参数的选择源自模拟退火的思想
![image](7CBB8A5333044E1BB3C45C74906BF88B)

